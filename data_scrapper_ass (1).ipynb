{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccf022df-ca74-4caa-989e-89d610e5c179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1\n",
    "# Web scraping is the process of automatically extracting data from websites. It involves using a program or script to access web pages, download their contents, and then extract specific information from the HTML or other structured data formats. \n",
    "\n",
    "# Web scraping is used for a variety of reasons due to its capability to quickly and efficiently gather data from websites. Here are some common reasons why web scraping is employed:\n",
    "# Data Collection and Analysis\n",
    "# Market Research and Competitor Analysis\n",
    "# Lead Generation \n",
    "# Content Aggregation\n",
    "\n",
    "# three areas where web scraping is commonly used to gather data:\n",
    "# E-commerce and Price Comparison\n",
    "# social Media Monitoring and Sentiment Analysis\n",
    "# Financial and Investment Research:\n",
    "\n",
    "\n",
    "#Q2\n",
    "\n",
    "# Here are the different methods commonly used for web scraping:\n",
    "\n",
    "# Using Python Libraries:\n",
    "# Beautiful Soup\n",
    "# Requests\n",
    "# Scrapy\n",
    "\n",
    "# Using Web Scraping Tools:\n",
    "# Octoparse\n",
    "# ParseHub\n",
    "# Import.io\n",
    "\n",
    "# API-based Scraping:\n",
    "# Using public APIs to access and retrieve data from websites.\n",
    "\n",
    "# Regex-based Scraping:\n",
    "# Regular expressions to parse and extract data from HTML content.\n",
    "\n",
    "# Headless Browsers:\n",
    "# Selenium with WebDriver\n",
    "# Puppeteer\n",
    "\n",
    "# HTML Parsing Libraries:\n",
    "# lxml\n",
    "# jsoup (Java)\n",
    "# Data Extraction Services:\n",
    "# Web scraping services and platforms that offer data extraction capabilities.\n",
    "\n",
    "# Custom Scripts:\n",
    "# Writing custom scripts in languages like Python, JavaScript, or Ruby to scrape data.\n",
    "# Proxy Rotations and CAPTCHA Solving:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01936c2b-bd10-4758-bc0b-7465ec84380d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2\n",
    "# Beautiful Soup is a Python library used for web scraping.It allows you to extract data from HTML and XML documents in a simple and intuitive way. \n",
    "# beautiful Soup simplifies the process of parsing HTML, making it easy for developers to extract information from web pages without dealing with the complexities of parsing raw HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "469eca23-43f4-426c-9a6d-1d0e69bbcada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3 Flask is used in this web scraping project to create a web application or API that allows users to interact with the scraped data. It provides a lightweight and easy-to-use framework for building web applications in Python. By integrating Flask, the scraped data can be presented to users in a user-friendly format, such as a web page or API endpoints, allowing them to access and utilize the scraped data easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfb39f9-e0b0-4eb2-b052-68a7126bc8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4\n",
    "# AWS SERVICES USED IN THIS PROJECT\n",
    "AWS CodePipeline:\n",
    "    # AWS CodePipeline is a continuous integration and continuous delivery (CI/CD) service provided by Amazon Web Services. It helps automate the process of building, testing, and deploying code changes across various stages of the software development lifecycle. \n",
    "     (in this project github connected to aws through codepipline)\n",
    "AWS Beanstalk:\n",
    "    # AWS Elastic Beanstalk is a Platform as a Service (PaaS) offering that simplifies application deployment and management. It allows developers to quickly deploy and manage applications without worrying about the underlying infrastructure setup.\n",
    "    (in this project beanstack provides us inviroment and  we integrate githut to beanstack thorugh beanstack and deploye code then our code is public so anyone can access it  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
